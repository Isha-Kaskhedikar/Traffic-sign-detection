{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,MaxPooling2D,Conv2D,Dropout\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"E:/sem V/DL and FL/train4\"\n",
    "# train_path = '/content/drive/MyDrive/train4'\n",
    "valid_path = '/content/dataset/acc-german-traffic-sign-classification2/GTSRB_Challenge/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 220, 220, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 108, 108, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 149,685\n",
      "Trainable params: 149,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "# vgg = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "# for layer in vgg.layers:\n",
    "#   layer.trainable = False\n",
    "  \n",
    "\n",
    "  \n",
    "  # useful for getting number of classes\n",
    "folders = glob('/content/drive/MyDrive/train4/*')\n",
    "  \n",
    "\n",
    "# our layers - you can add more if you want\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dense(256 ,activation='relu')(x)\n",
    "# x = Dense(256 ,activation='relu')(x)\n",
    "# x = Flatten()(vgg.output)\n",
    "# prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x000001D207FF7FA0>\n",
      "Found 4500 images belonging to 21 classes.\n",
      "Found 1122 images belonging to 21 classes.\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 420s 1s/step - loss: 0.1263 - accuracy: 0.9571 - val_loss: 0.1009 - val_accuracy: 0.9722\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 315s 840ms/step - loss: 0.1252 - accuracy: 0.9604 - val_loss: 0.3233 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 218s 581ms/step - loss: 0.1232 - accuracy: 0.9611 - val_loss: 0.1290 - val_accuracy: 0.9653\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 213s 566ms/step - loss: 0.1105 - accuracy: 0.9664 - val_loss: 0.1362 - val_accuracy: 0.9583\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 208s 555ms/step - loss: 0.1132 - accuracy: 0.9649 - val_loss: 0.1432 - val_accuracy: 0.9514\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 207s 552ms/step - loss: 0.0958 - accuracy: 0.9693 - val_loss: 0.3076 - val_accuracy: 0.9097\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 206s 549ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.1621 - val_accuracy: 0.9514\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 199s 531ms/step - loss: 0.0925 - accuracy: 0.9729 - val_loss: 0.2692 - val_accuracy: 0.9028\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 195s 520ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 0.2843 - val_accuracy: 0.9236\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 190s 507ms/step - loss: 0.0910 - accuracy: 0.9713 - val_loss: 0.1293 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "# vgg = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "# for layâ€¦\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "print(test_datagen)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 12,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                subset='training')\n",
    "validation_set = train_datagen.flow_from_directory(\n",
    "    train_path, # same directory as training data\n",
    "    target_size = (224, 224),\n",
    "    batch_size=12,\n",
    "    class_mode = 'categorical',\n",
    "    subset='validation',\n",
    "shuffle=True) # set as validation data\n",
    "# test_set = test_datagen.flow_from_directory('/content/dataset/acc-german-traffic-sign-classification2/GTSRB_Challenge/test',\n",
    "#                                             target_size = (224, 224),\n",
    "#                                             batch_size = 12,\n",
    "#                                             class_mode = 'categorical')\n",
    "\n",
    "'''r=model.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)'''\n",
    "\n",
    "# fit the model\n",
    "r = model.fit(\n",
    "  training_set,\n",
    "  validation_data=validation_set,\n",
    "  epochs=10,\n",
    "  # steps_per_epoch=len(training_set),\n",
    "  validation_steps=12\n",
    ")\n",
    "# loss\n",
    "# plt.plot(r.history['loss'], label='train loss')\n",
    "# plt.plot(r.history['val_loss'], label='val loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# plt.savefig('LossVal_loss')\n",
    "\n",
    "# # accuracies\n",
    "# plt.plot(r.history['acc'], label='train acc')\n",
    "# plt.plot(r.history['val_acc'], label='val acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# plt.savefig('AccVal_acc')\n",
    "\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('signal_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
